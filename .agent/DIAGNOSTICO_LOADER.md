# üîç DIAGN√ìSTICO PROFUNDO: PROBLEMA DEL LOADER

**Fecha:** 2025-12-25 16:42:00  
**Problema:** Alta tasa de omisi√≥n (~45%) en el loader  
**Causa Ra√≠z Identificada:** Transacciones abortadas en cascada

---

## üêõ PROBLEMA IDENTIFICADO

### Error Principal:
```
InternalError: (psycopg2.errors.InFailedSqlTransaction) 
current transaction is aborted, commands ignored until end of transaction block
```

### Estad√≠sticas:
- **Archivo:** raw_products_20251214.jsonl
- **Errores totales:** 26,574
- **Tipo de error:** 100% InternalError (transacci√≥n abortada)
- **Tasa de omisi√≥n:** ~45%

---

## üîç AN√ÅLISIS DEL PROBLEMA

### Flujo del Error:

```
1. Loader procesa registro A ‚Üí OK
2. Loader procesa registro B ‚Üí ERROR (causa desconocida)
3. Transacci√≥n se aborta
4. session.rollback() se ejecuta
5. Loader procesa registro C ‚Üí FALLA (transacci√≥n abortada)
6. Loader procesa registro D ‚Üí FALLA (transacci√≥n abortada)
7. ... todos los registros subsecuentes fallan en cascada
```

### Problema:
Despu√©s de `session.rollback()`, la transacci√≥n queda en estado "aborted" y **TODOS** los comandos SQL subsecuentes fallan con `InternalError`, incluso si son v√°lidos.

---

## ‚ùå SOLUCI√ìN INTENTADA (NO FUNCION√ì)

### C√≥digo agregado:
```python
session.rollback()
session.begin()  # ‚Üê Esto no funciona con SQLAlchemy
```

### Por qu√© no funcion√≥:
SQLAlchemy maneja las transacciones autom√°ticamente. Llamar a `session.begin()` manualmente puede causar conflictos.

---

## ‚úÖ SOLUCI√ìN CORRECTA

### Opci√≥n 1: Commit despu√©s de Rollback (RECOMENDADA)
```python
except Exception as e:
    stats["error"] += 1
    session.rollback()
    session.commit()  # Finaliza la transacci√≥n abortada
    # La pr√≥xima operaci√≥n iniciar√° una nueva transacci√≥n autom√°ticamente
```

### Opci√≥n 2: Usar Savepoints
```python
# Antes del try
savepoint = session.begin_nested()

try:
    self.ingest_record(record, session)
    stats["ok"] += 1
except Exception as e:
    savepoint.rollback()  # Solo rollback del savepoint, no de toda la transacci√≥n
    stats["error"] += 1
```

### Opci√≥n 3: Transacci√≥n Individual por Registro
```python
try:
    self.ingest_record(record, session)
    session.commit()  # Commit inmediato
    stats["ok"] += 1
except Exception as e:
    session.rollback()
    stats["error"] += 1
```

---

## üéØ RECOMENDACI√ìN

**Usar Opci√≥n 1** (Commit despu√©s de Rollback) porque:
- ‚úÖ Simple y directo
- ‚úÖ Compatible con SQLAlchemy
- ‚úÖ No afecta el rendimiento significativamente
- ‚úÖ Permite commits por lotes (cada 100 registros)

---

## üîß C√ìDIGO CORREGIDO

```python
try:
    record = json.loads(line)
    self.ingest_record(record, session)
    stats["ok"] += 1
    
    # Commit por lotes
    if stats["ok"] % 100 == 0: 
        session.commit()
        self.print_batch_summary(filepath.name, stats)
        
except Exception as e:
    # Contar tipo de error
    error_type = type(e).__name__
    error_types[error_type] = error_types.get(error_type, 0) + 1
    
    # Guardar primeros 10 errores para an√°lisis
    if len(error_samples) < 10:
        error_samples.append({
            "type": error_type,
            "message": str(e)[:200],
            "record_id": record.get("id") if isinstance(record, dict) else None
        })
    
    stats["error"] += 1
    session.rollback()
    session.commit()  # ‚Üê CR√çTICO: Finalizar transacci√≥n abortada
```

---

## üö® ERROR ORIGINAL (A√öN POR IDENTIFICAR)

El `InternalError` es un **error secundario** causado por la transacci√≥n abortada.

**Necesitamos identificar el error ORIGINAL** que causa el primer abort.

### Hip√≥tesis:
1. **Constraint violation** (FK, unique, not null)
2. **Data type mismatch** (string donde se espera int)
3. **Encoding issues** (caracteres especiales)
4. **Null en campo requerido**

### Para identificarlo:
Necesitamos capturar el **primer error** antes de que la cascada comience.

---

## üìä IMPACTO ESPERADO

### Antes del Fix:
- Tasa de √©xito: ~55%
- Tasa de error: ~45%
- Productos insertados: 377

### Despu√©s del Fix (Estimado):
- Tasa de √©xito: ~95%+ (solo errores reales)
- Tasa de error: ~5% (datos realmente inv√°lidos)
- Productos insertados: ~6,000+ (de 6,831 scrapeados)

---

**Pr√≥ximo paso:** Aplicar fix correcto y monitorear resultados
